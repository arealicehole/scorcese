https://github.com/elevenlabs/elevenlabs-python
https://pypi.org/project/elevenlabs/

---
title: Developer quickstart
subtitle: Learn how to make your first ElevenLabs API request.
---

The ElevenLabs API provides a simple interface to state-of-the-art audio [models](/docs/overview/models) and [features](/docs/api-reference/introduction). Follow this guide to learn how to create lifelike speech with our Text to Speech API. See the [developer guides](/docs/developers/quickstart#explore-our-developer-guides) for more examples with our other products.

## Using the Text to Speech API

<Steps>
    <Step title="Create an API key">
      [Create an API key in the dashboard here](https://elevenlabs.io/app/settings/api-keys), which youâ€™ll use to securely [access the API](/docs/api-reference/authentication).
      
      Store the key as a managed secret and pass it to the SDKs either as a environment variable via an `.env` file, or directly in your appâ€™s configuration depending on your preference.
      
      ```js title=".env"
      ELEVENLABS_API_KEY=<your_api_key_here>
      ```
      
    </Step>
    <Step title="Install the SDK">
      We'll also use the `dotenv` library to load our API key from an environment variable.
      
      <CodeBlocks>
          ```python
          pip install elevenlabs
          pip install python-dotenv
          ```
      
          ```typescript
          npm install @elevenlabs/elevenlabs-js
          npm install dotenv
          ```
      
      </CodeBlocks>
      

      <Note>
        To play the audio through your speakers, you may be prompted to install [MPV](https://mpv.io/)
      and/or [ffmpeg](https://ffmpeg.org/).
      </Note>
    </Step>
    <Step title="Make your first request">
      Create a new file named `example.py` or `example.mts`, depending on your language of choice and add the following code:
       {/* This snippet was auto-generated */}
       <CodeBlocks>
       ```python
       from dotenv import load_dotenv
       from elevenlabs.client import ElevenLabs
       from elevenlabs.play import play
       import os
       
       load_dotenv()
       
       elevenlabs = ElevenLabs(
         api_key=os.getenv("ELEVENLABS_API_KEY"),
       )
       
       audio = elevenlabs.text_to_speech.convert(
           text="The first move is what sets everything in motion.",
           voice_id="JBFqnCBsd6RMkjVDRZzb",
           model_id="eleven_multilingual_v2",
           output_format="mp3_44100_128",
       )
       
       play(audio)
       
       ```
       
       ```typescript
       import { ElevenLabsClient, play } from '@elevenlabs/elevenlabs-js';
       import { Readable } from 'stream';
       import 'dotenv/config';
       
       const elevenlabs = new ElevenLabsClient();
       const audio = await elevenlabs.textToSpeech.convert('JBFqnCBsd6RMkjVDRZzb', {
         text: 'The first move is what sets everything in motion.',
         modelId: 'eleven_multilingual_v2',
         outputFormat: 'mp3_44100_128',
       });
       
       const reader = audio.getReader();
       const stream = new Readable({
         async read() {
           const { done, value } = await reader.read();
           if (done) {
             this.push(null);
           } else {
             this.push(value);
           }
         },
       });
       
       await play(stream);
       
       ```
       
       </CodeBlocks>
    </Step>
    <Step title="Run the code">
        <CodeBlocks>
            ```python
            python example.py
            ```

            ```typescript
            npx tsx example.mts
            ```
        </CodeBlocks>

        You should hear the audio play through your speakers.
    </Step>

</Steps>

## Explore our developer guides

Now that you've made your first ElevenLabs API request, you can explore the other products that ElevenLabs offers.

<CardGroup cols={2}>
  <Card
    title="Speech to Text"
    icon="duotone pen-clip"
    href="/docs/developers/guides/cookbooks/speech-to-text/quickstart"
  >
    Convert spoken audio into text
  </Card>
  <Card
    title="Music"
    icon="duotone music"
    href="/docs/developers/guides/cookbooks/music/quickstart"
  >
    Generate studio-quality music
  </Card>
  <Card
    title="Text to Dialogue"
    icon="duotone comment-dots"
    href="/docs/developers/guides/cookbooks/text-to-dialogue"
  >
    Create natural-sounding dialogue from text
  </Card>
  <Card
    title="Voice Changer"
    icon="duotone message-pen"
    href="/docs/developers/guides/cookbooks/voice-changer"
  >
    Transform the voice of an audio file
  </Card>
  <Card
    title="Voice Isolator"
    icon="duotone ear"
    href="/docs/developers/guides/cookbooks/voice-isolator"
  >
    Isolate background noise from audio
  </Card>
  <Card title="Dubbing" icon="duotone language" href="/docs/developers/guides/cookbooks/dubbing">
    Dub audio/video from one language to another
  </Card>
  <Card
    title="Sound Effects"
    icon="duotone explosion"
    href="/docs/developers/guides/cookbooks/sound-effects"
  >
    Generate sound effects from text
  </Card>
  <Card
    title="Voice Cloning"
    icon="duotone clone"
    href="/docs/developers/guides/cookbooks/voices/instant-voice-cloning"
  >
    Clone a voice
  </Card>
  <Card
    title="Voice Remixing"
    icon="duotone shuffle"
    href="/docs/developers/guides/cookbooks/voices/remix-a-voice"
  >
    Remix a voice
  </Card>

<Card
title="Voice Design"
icon="duotone paint-brush"
href="/docs/developers/guides/cookbooks/voices/voice-design"
>

    Generate voices from a single text prompt

  </Card>
  <Card
    title="Forced Alignment"
    icon="duotone objects-align-left"
    href="/docs/developers/guides/cookbooks/forced-alignment"
  >
    Generate time-aligned transcripts for audio
  </Card>
  <Card title="ElevenLabs Agents" icon="duotone comments" href="/docs/agents-platform/quickstart">
    Deploy conversational voice agents
  </Card>
</CardGroup>

---
title: Voice Changer quickstart
subtitle: Learn how to transform the voice of an audio file using the Voice Changer API.
---

This guide will show you how to transform the voice of an audio file using the Voice Changer API.

## Using the Voice Changer API

<Steps>
    <Step title="Create an API key">
        [Create an API key in the dashboard here](https://elevenlabs.io/app/settings/api-keys), which youâ€™ll use to securely [access the API](/docs/api-reference/authentication).
        
        Store the key as a managed secret and pass it to the SDKs either as a environment variable via an `.env` file, or directly in your appâ€™s configuration depending on your preference.
        
        ```js title=".env"
        ELEVENLABS_API_KEY=<your_api_key_here>
        ```
        
    </Step>
    <Step title="Install the SDK">
        We'll also use the `dotenv` library to load our API key from an environment variable.
        
        <CodeBlocks>
            ```python
            pip install elevenlabs
            pip install python-dotenv
            ```
        
            ```typescript
            npm install @elevenlabs/elevenlabs-js
            npm install dotenv
            ```
        
        </CodeBlocks>
        

        <Note>
            To play the audio through your speakers, you may be prompted to install [MPV](https://mpv.io/)
            and/or [ffmpeg](https://ffmpeg.org/).
        </Note>
    </Step>
    <Step title="Make the API request">
        Create a new file named `example.py` or `example.mts`, depending on your language of choice and add the following code:

        <CodeBlocks>
        ```python maxLines=0
        # example.py
        import os
        from dotenv import load_dotenv
        from elevenlabs.client import ElevenLabs
        from elevenlabs.play import play
        import requests
        from io import BytesIO

        load_dotenv()

        elevenlabs = ElevenLabs(
          api_key=os.getenv("ELEVENLABS_API_KEY"),
        )
        voice_id = "JBFqnCBsd6RMkjVDRZzb"

        audio_url = (
            "https://storage.googleapis.com/eleven-public-cdn/audio/marketing/nicole.mp3"
        )
        response = requests.get(audio_url)
        audio_data = BytesIO(response.content)

        audio_stream = elevenlabs.speech_to_speech.convert(
            voice_id=voice_id,
            audio=audio_data,
            model_id="eleven_multilingual_sts_v2",
            output_format="mp3_44100_128",
        )

        play(audio_stream)
        ```

        ```typescript maxLines=0
        // example.mts
        import { ElevenLabsClient, play } from "@elevenlabs/elevenlabs-js";
        import "dotenv/config";

        const elevenlabs = new ElevenLabsClient();
        const voiceId = "JBFqnCBsd6RMkjVDRZzb";

        const response = await fetch(
          "https://storage.googleapis.com/eleven-public-cdn/audio/marketing/nicole.mp3"
        );
        const audioBlob = new Blob([await response.arrayBuffer()], { type: "audio/mp3" });

        const audioStream = await elevenlabs.speechToSpeech.convert(voiceId, {
          audio: audioBlob,
          modelId: "eleven_multilingual_sts_v2",
          outputFormat: "mp3_44100_128",
        });

        await play(audioStream);
        ```
        </CodeBlocks>
    </Step>
    <Step title="Execute the code">
        <CodeBlocks>
            ```python
            python example.py
            ```

            ```typescript
            npx tsx example.mts
            ```
        </CodeBlocks>

        You should hear the transformed voice playing through your speakers.
    </Step>

</Steps>

## Next steps

Explore the [API reference](/docs/api-reference/speech-to-speech/convert) for more information on the Voice Changer API and its options.

---
title: Sound Effects quickstart
subtitle: Learn how to generate sound effects using the Sound Effects API.
---

This guide will show you how to generate sound effects using the Sound Effects API.

## Using the Sound Effects API

<Steps>
    <Step title="Create an API key">
        [Create an API key in the dashboard here](https://elevenlabs.io/app/settings/api-keys), which youâ€™ll use to securely [access the API](/docs/api-reference/authentication).
        
        Store the key as a managed secret and pass it to the SDKs either as a environment variable via an `.env` file, or directly in your appâ€™s configuration depending on your preference.
        
        ```js title=".env"
        ELEVENLABS_API_KEY=<your_api_key_here>
        ```
        
    </Step>
    <Step title="Install the SDK">
        We'll also use the `dotenv` library to load our API key from an environment variable.
        
        <CodeBlocks>
            ```python
            pip install elevenlabs
            pip install python-dotenv
            ```
        
            ```typescript
            npm install @elevenlabs/elevenlabs-js
            npm install dotenv
            ```
        
        </CodeBlocks>
        

        <Note>
            To play the audio through your speakers, you may be prompted to install [MPV](https://mpv.io/)
            and/or [ffmpeg](https://ffmpeg.org/).
        </Note>
    </Step>
    <Step title="Make the API request">
        Create a new file named `example.py` or `example.mts`, depending on your language of choice and add the following code:

        <CodeBlocks>
        ```python maxLines=0
        # example.py
        import os
        from dotenv import load_dotenv
        from elevenlabs.client import ElevenLabs
        from elevenlabs.play import play

        load_dotenv()

        elevenlabs = ElevenLabs(
          api_key=os.getenv("ELEVENLABS_API_KEY"),
        )
        audio = elevenlabs.text_to_sound_effects.convert(text="Cinematic Braam, Horror")

        play(audio)
        ```

        ```typescript
        // example.mts
        import { ElevenLabsClient, play } from "@elevenlabs/elevenlabs-js";
        import "dotenv/config";

        const elevenlabs = new ElevenLabsClient();

        const audio = await elevenlabs.textToSoundEffects.convert({
          text: "Cinematic Braam, Horror",
        });

        await play(audio);
        ```
        </CodeBlocks>
    </Step>
    <Step title="Execute the code">
        <CodeBlocks>
            ```python
            python example.py
            ```

            ```typescript
            npx tsx example.mts
            ```
        </CodeBlocks>

        You should hear your generated sound effect playing through your speakers.
    </Step>

</Steps>

## Next steps

Explore the [API reference](/docs/api-reference/speech-to-text/convert) for more information on the Speech to Text API and its options.


Project description
ElevenLabs Python Library

LOGO

fern shield Discord Twitter PyPI - Python Version Downloads

The official Python SDK for ElevenLabs. ElevenLabs brings the most compelling, rich and lifelike voices to creators and developers in just a few lines of code.
ðŸ“– API & Docs

Check out the HTTP API documentation.
Install

pip install elevenlabs

Usage
Main Models

    Eleven Multilingual v2 (eleven_multilingual_v2)
        Excels in stability, language diversity, and accent accuracy
        Supports 29 languages
        Recommended for most use cases

    Eleven Flash v2.5 (eleven_flash_v2_5)
        Ultra-low latency
        Supports 32 languages
        Faster model, 50% lower price per character

    Eleven Turbo v2.5 (eleven_turbo_v2_5)
        Good balance of quality and latency
        Ideal for developer use cases where speed is crucial
        Supports 32 languages

For more detailed information about these models and others, visit the ElevenLabs Models documentation.

from dotenv import load_dotenv
from elevenlabs.client import ElevenLabs
from elevenlabs.play import play

load_dotenv()

client = ElevenLabs()

audio = client.text_to_speech.convert(
    text="The first move is what sets everything in motion.",
    voice_id="JBFqnCBsd6RMkjVDRZzb",
    model_id="eleven_multilingual_v2",
    output_format="mp3_44100_128",
)

play(audio)

Play

Voices

List all your available voices with voices().

from elevenlabs.client import ElevenLabs

client = ElevenLabs(
  api_key="YOUR_API_KEY",
)

response = client.voices.search()
print(response.voices)

For information about the structure of the voices output, please refer to the official ElevenLabs API documentation for Get Voices.

Build a voice object with custom settings to personalize the voice style, or call client.voices.get_settings("your-voice-id") to get the default settings for the voice.
Clone Voice

Clone your voice in an instant. Note that voice cloning requires an API key, see below.

from elevenlabs.client import ElevenLabs
from elevenlabs.play import play

client = ElevenLabs(
  api_key="YOUR_API_KEY",
)

voice = client.voices.ivc.create(
    name="Alex",
    description="An old American male voice with a slight hoarseness in his throat. Perfect for news", # Optional
    files=["./sample_0.mp3", "./sample_1.mp3", "./sample_2.mp3"],
)

Streaming

Stream audio in real-time, as it's being generated.

from elevenlabs import stream
from elevenlabs.client import ElevenLabs

client = ElevenLabs()

audio_stream = client.text_to_speech.stream(
    text="This is a test",
    voice_id="JBFqnCBsd6RMkjVDRZzb",
    model_id="eleven_multilingual_v2"
)

# option 1: play the streamed audio locally
stream(audio_stream)

# option 2: process the audio bytes manually
for chunk in audio_stream:
    if isinstance(chunk, bytes):
        print(chunk)

Async Client

Use AsyncElevenLabs if you want to make API calls asynchronously.

import asyncio

from elevenlabs.client import AsyncElevenLabs

eleven = AsyncElevenLabs(
  api_key="MY_API_KEY"
)

async def print_models() -> None:
    models = await eleven.models.list()
    print(models)

asyncio.run(print_models())

Conversational AI

Build interactive AI agents with real-time audio capabilities using ElevenLabs Conversational AI.
Basic Usage

from elevenlabs.client import ElevenLabs
from elevenlabs.conversational_ai.conversation import Conversation, ClientTools
from elevenlabs.conversational_ai.default_audio_interface import DefaultAudioInterface

client = ElevenLabs(api_key="YOUR_API_KEY")

# Create audio interface for real-time audio input/output
audio_interface = DefaultAudioInterface()

# Create conversation
conversation = Conversation(
    client=client,
    agent_id="your-agent-id",
    requires_auth=True,
    audio_interface=audio_interface,
)

# Start the conversation
conversation.start_session()

# The conversation runs in background until you call:
conversation.end_session()

Custom Event Loop Support

For advanced use cases involving context propagation, resource reuse, or specific event loop management, ClientTools supports custom asyncio event loops:

import asyncio
from elevenlabs.conversational_ai.conversation import ClientTools

async def main():
    # Get the current event loop
    custom_loop = asyncio.get_running_loop()

    # Create ClientTools with custom loop to prevent "different event loop" errors
    client_tools = ClientTools(loop=custom_loop)

    # Register your tools
    async def get_weather(params):
        location = params.get("location", "Unknown")
        # Your async logic here
        return f"Weather in {location}: Sunny, 72Â°F"

    client_tools.register("get_weather", get_weather, is_async=True)

    # Use with conversation
    conversation = Conversation(
        client=client,
        agent_id="your-agent-id",
        requires_auth=True,
        audio_interface=audio_interface,
        client_tools=client_tools
    )

asyncio.run(main())

Benefits of Custom Event Loop:

    Context Propagation: Maintain request-scoped state across async operations
    Resource Reuse: Share existing async resources like HTTP sessions or database pools
    Loop Management: Prevent "Task got Future attached to a different event loop" errors
    Performance: Better control over async task scheduling and execution

Important: When using a custom loop, you're responsible for its lifecycle Don't close the loop while ClientTools are still using it.
Tool Registration

Register custom tools that the AI agent can call during conversations:

client_tools = ClientTools()

# Sync tool
def calculate_sum(params):
    numbers = params.get("numbers", [])
    return sum(numbers)

# Async tool
async def fetch_data(params):
    url = params.get("url")
    # Your async HTTP request logic
    return {"data": "fetched"}

client_tools.register("calculate_sum", calculate_sum, is_async=False)
client_tools.register("fetch_data", fetch_data, is_async=True)
